{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7abb53a",
   "metadata": {},
   "source": [
    "# UCF-Crime Anomaly Detection with Multi-Task Learning\n",
    "\n",
    "This Jupyter Notebook implements a Multi-Task Learning (MTL) pipeline for anomaly detection using an image-based UCF-Crime dataset. The pipeline processes `.png` images, trains a model with four tasks (general anomaly detection, violence detection, property crime detection, anomaly type classification), analyzes task relationships, and conducts an ablation study. The dataset is assumed to be at `/home/user/ucf_crime_dataset` with generated annotation files.\n",
    "\n",
    "## Setup Instructions\n",
    "1. Install dependencies: `pip install tensorflow opencv-python numpy pandas scikit-learn scipy`\n",
    "2. Download the Kaggle dataset: https://www.kaggle.com/datasets/mission-ai/crimeucfdataset\n",
    "3. Extract `.png` images or use `extract_frames.py` to convert videos to images.\n",
    "4. Update paths in cells as needed (e.g., `data_dir`).\n",
    "5. Run cells sequentially, inspecting outputs for debugging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d12656",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5f007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.stats import pearsonr\n",
    "import csv\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f31cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subfolders:  ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Test subfolders:  ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Setup complete. Dataset directory: D:/Users/eniang.eniang/Desktop/Multi-task learning/data/\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "DATA_DIR = 'D:/Users/eniang.eniang/Desktop/Multi-task learning/data/'  # Update to your dataset path\n",
    "TRAIN_ANNOTATION_FILE = 'train_annotations.txt'\n",
    "TEST_ANNOTATION_FILE = 'test_annotations.txt'\n",
    "IMAGE_SIZE = (224, 224)  # Image size for ResNet50\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "NUM_ANOMALY_TYPES = 14  # 13 anomaly classes + Normal\n",
    "\n",
    "# Verify dataset directory\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise ValueError(f\"Dataset directory {DATA_DIR} does not exist. Update DATA_DIR.\")\n",
    "\n",
    "# check train and test directories\n",
    "train_dir = os.path.join(DATA_DIR, \"Train\")\n",
    "test_dir = os.path.join(DATA_DIR, \"Test\")\n",
    "\n",
    "print(\"Train subfolders: \", os.listdir(train_dir) if os.path.exists(train_dir) else \"Not found\")\n",
    "print(\"Test subfolders: \", os.listdir(test_dir) if os.path.exists(test_dir) else \"Not found\")\n",
    "\n",
    "print(\"Setup complete. Dataset directory:\", DATA_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848ac88",
   "metadata": {},
   "source": [
    "# Stage 2: Annotation Generation\n",
    "Generate annotation files (train_annotations.txt, test_annotations.txt) for the image-based dataset, mapping .png images to class labels based on folder structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12395d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training annotations..........\n",
      "Found 14 class subfolders in D:/Users/eniang.eniang/Desktop/Multi-task learning/data/Train: ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Generated train_annotations.txt with 2532690 entries\n",
      "Images per class in Train: {'Abuse': 38152, 'Arrest': 52794, 'Arson': 48842, 'Assault': 20720, 'Burglary': 79008, 'Explosion': 37506, 'Fighting': 49368, 'NormalVideos': 1895536, 'RoadAccidents': 46972, 'Robbery': 82986, 'Shooting': 14280, 'Shoplifting': 49670, 'Stealing': 89604, 'Vandalism': 27252}\n",
      "Sample annotations (first 5): ['\"Train\\\\Abuse\\\\Abuse001_x264_0.png\" Abuse', '\"Train\\\\Abuse\\\\Abuse001_x264_10.png\" Abuse', '\"Train\\\\Abuse\\\\Abuse001_x264_100.png\" Abuse', '\"Train\\\\Abuse\\\\Abuse001_x264_1000.png\" Abuse', '\"Train\\\\Abuse\\\\Abuse001_x264_1010.png\" Abuse']\n",
      "Generating test annotations..............\n",
      "Found 14 class subfolders in D:/Users/eniang.eniang/Desktop/Multi-task learning/data/Test: ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Generated test_annotations.txt with 222616 entries\n",
      "Images per class in Test: {'Abuse': 594, 'Arrest': 6730, 'Arson': 5586, 'Assault': 5314, 'Burglary': 15314, 'Explosion': 13020, 'Fighting': 2462, 'NormalVideos': 129904, 'RoadAccidents': 5326, 'Robbery': 1670, 'Shooting': 15260, 'Shoplifting': 15246, 'Stealing': 3968, 'Vandalism': 2222}\n",
      "Sample annotations (first 5): ['\"Test\\\\Abuse\\\\Abuse028_x264_0.png\" Abuse', '\"Test\\\\Abuse\\\\Abuse028_x264_10.png\" Abuse', '\"Test\\\\Abuse\\\\Abuse028_x264_100.png\" Abuse', '\"Test\\\\Abuse\\\\Abuse028_x264_1000.png\" Abuse', '\"Test\\\\Abuse\\\\Abuse028_x264_1010.png\" Abuse']\n",
      "\n",
      "Annotation files created successfully.\n",
      "First 5 lines of the train_annotation.txt:\n",
      "['\"Train\\\\Abuse\\\\Abuse001_x264_0.png\" Abuse\\n', '\"Train\\\\Abuse\\\\Abuse001_x264_10.png\" Abuse\\n', '\"Train\\\\Abuse\\\\Abuse001_x264_100.png\" Abuse\\n', '\"Train\\\\Abuse\\\\Abuse001_x264_1000.png\" Abuse\\n', '\"Train\\\\Abuse\\\\Abuse001_x264_1010.png\" Abuse\\n']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def generate_annotation_file(dataset_root, split, output_file):\n",
    "    \"\"\"\n",
    "    Generate an annotation file for a given dataset split (train or test) with .png images.\n",
    "    \"\"\"\n",
    "    split_dir = os.path.join(dataset_root, split)\n",
    "    if not os.path.exists(split_dir):\n",
    "        raise ValueError(f\"Directory {split_dir} does not exist.\")\n",
    "    \n",
    "    annotations = []\n",
    "    class_counts = {}\n",
    "\n",
    "    # List the class subfolders\n",
    "    class_names = [name for name in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, name))]\n",
    "    print(f\"Found {len(class_names)} class subfolders in {split_dir}: {class_names}\")\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(split_dir, class_name)\n",
    "\n",
    "        # Find the images with multiple extensions\n",
    "        image_files = []\n",
    "        for ext in [\"*.jpg\", \"*.PNG\", \"*.png\", \"*.JPG\"]:\n",
    "            image_files.extend(glob.glob(os.path.join(class_dir, ext)))\n",
    "\n",
    "        class_counts[class_name] = len(image_files)\n",
    "\n",
    "        for image_path in image_files:\n",
    "            # construct relative path\n",
    "            relative_path = os.path.join(split, class_name, os.path.basename(image_path))\n",
    "            # Quote path to handle spaces\n",
    "            annotation = f'\"{relative_path}\" {class_name}'\n",
    "            annotations.append(annotation)\n",
    "\n",
    "    # Write the annotations\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for annotation in annotations:\n",
    "            f.write(annotation + '\\n')\n",
    "    \n",
    "    # debugging output\n",
    "    print(f\"Generated {output_file} with {len(annotations)} entries\")\n",
    "    print(f\"Images per class in {split}:\", class_counts)\n",
    "    if annotations:\n",
    "        print(\"Sample annotations (first 5):\", annotations[:5])\n",
    "    if not annotations:\n",
    "        print(\"WARNING!!! no images found\")\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "\n",
    "# Generate Annotations\n",
    "print(\"Generating training annotations..........\")\n",
    "train_class_counts = generate_annotation_file(DATA_DIR, \"Train\", TRAIN_ANNOTATION_FILE)\n",
    "print(\"Generating test annotations..............\")\n",
    "test_class_counts = generate_annotation_file(DATA_DIR, \"Test\", TEST_ANNOTATION_FILE)\n",
    "\n",
    "# verify annotation files\n",
    "if os.path.exists(TRAIN_ANNOTATION_FILE) and os.path.exists(TEST_ANNOTATION_FILE):\n",
    "    print(\"\\nAnnotation files created successfully.\")\n",
    "    print(\"First 5 lines of the train_annotation.txt:\")\n",
    "    with open(TRAIN_ANNOTATION_FILE, 'r') as f:\n",
    "        print(f.readlines()[:5])\n",
    "\n",
    "else:\n",
    "    raise FileNotFoundError(\"Annotation file not found. Check generation process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39573c",
   "metadata": {},
   "source": [
    "# Stage 3: Data Loading\n",
    "Load .png images and labels from the annotation files using load_ucf_crime_data. Outputs the number of loaded images and label shapes for debugging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1172c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data .....\n",
      "Loaded annotation file: train_annotations.txt\n",
      "First 5 entries:                                 image  label\n",
      "0     Train\\Abuse\\Abuse001_x264_0.png  Abuse\n",
      "1    Train\\Abuse\\Abuse001_x264_10.png  Abuse\n",
      "2   Train\\Abuse\\Abuse001_x264_100.png  Abuse\n",
      "3  Train\\Abuse\\Abuse001_x264_1000.png  Abuse\n",
      "4  Train\\Abuse\\Abuse001_x264_1010.png  Abuse\n",
      "The total annotations: 2532690\n",
      "Valid images: 2532690\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"D:\\Users\\eniang.eniang\\AppData\\Local\\Temp\\2\\ipykernel_5628\\2460950749.py\", line 49, in process_path  *\n        anomaly_type = tf.where(tf.reduce_any(matches), anomaly_type, tf.cast(len(anomaly_classes),tf.int32))\n\n    TypeError: Input 'e' of 'SelectV2' Op has type int32 that does not match type int64 of argument 't'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data .....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_ucf_crime_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_ANNOTATION_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMAGE_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoading validation data............\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m load_ucf_crime_data(DATA_DIR, TEST_ANNOTATION_FILE, IMAGE_SIZE, BATCH_SIZE)\n",
      "Cell \u001b[1;32mIn[12], line 77\u001b[0m, in \u001b[0;36mload_ucf_crime_data\u001b[1;34m(data_dir, annotation_file, image_size, batch_size)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: No valid images found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((image_path, labels))\n\u001b[1;32m---> 77\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[0;32m     79\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2204\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2202\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2204\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2206\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2207\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2208\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2209\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2210\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5441\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m   5440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m-> 5441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5443\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5445\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5447\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32md:\\Users\\eniang.eniang\\AppData\\Local\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\2\\__autograph_generated_filerszns5ty.py:27\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__process_path\u001b[1;34m(image_path, label)\u001b[0m\n\u001b[0;32m     25\u001b[0m matches \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mequal, (ag__\u001b[38;5;241m.\u001b[39mld(anomaly_classes), ag__\u001b[38;5;241m.\u001b[39mld(label)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     26\u001b[0m anomaly_type \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_max, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mwhere, (ag__\u001b[38;5;241m.\u001b[39mld(matches),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 27\u001b[0m anomaly_type \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_any\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43manomaly_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43manomaly_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m anomaly_type \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(anomaly_type), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"D:\\Users\\eniang.eniang\\AppData\\Local\\Temp\\2\\ipykernel_5628\\2460950749.py\", line 49, in process_path  *\n        anomaly_type = tf.where(tf.reduce_any(matches), anomaly_type, tf.cast(len(anomaly_classes),tf.int32))\n\n    TypeError: Input 'e' of 'SelectV2' Op has type int32 that does not match type int64 of argument 't'.\n"
     ]
    }
   ],
   "source": [
    "# Stage 3: Data Loading\n",
    "def load_ucf_crime_data(data_dir, annotation_file, image_size=(224, 224), batch_size=32):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # verify the annotation file exists\n",
    "    if not os.path.exists(annotation_file):\n",
    "        raise FileNotFoundError(f\"Annotation file {annotation_file}  not found\")\n",
    "    \n",
    "    # Read annotation file\n",
    "    try:\n",
    "        annotations = pd.read_csv(annotation_file, sep=' ', header=None,\n",
    "        names=[\"image\", \"label\"], quotechar='\"')\n",
    "        print(f\"Loaded annotation file: {annotation_file}\")\n",
    "        print(f\"First 5 entries: {annotations.head()}\")\n",
    "        print(f\"The total annotations: {len(annotations)}\")\n",
    "    \n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing {annotation_file}: {e}\")\n",
    "        print(\"Check if file has spaces in filenames or incorrect delimiters.\")\n",
    "        raise\n",
    "\n",
    "    # Define anomaly classes\n",
    "    anomaly_classes = tf.constant(['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting','NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'])\n",
    "    violent_classes = tf.constant([\"Assault\", \"Fighting\", \"Shooting\"])\n",
    "    property_classes = tf.constant([\"Burglary\", \"Stealing\", \"Shoplifting\", \"Vandalism\"])\n",
    "\n",
    "    @tf.function\n",
    "    def process_path(image_path, label):\n",
    "        # Load and preprocess image\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_png(img,channels=3)\n",
    "        img = tf.image.resize(img, image_size)\n",
    "        img = img / 255.0\n",
    "        img = tf.cast(img, tf.float32)\n",
    "\n",
    "        # Assign labels\n",
    "        is_anomaly = tf.reduce_any(tf.equal(anomaly_classes, label))\n",
    "        is_anomaly = tf.cast(is_anomaly, tf.int32)\n",
    "\n",
    "        is_violent = tf.reduce_any(tf.equal(violent_classes, label))\n",
    "        is_violent = tf.cast(is_violent, tf.int32)\n",
    "\n",
    "        is_property = tf.reduce_any(tf.equal(property_classes, label))\n",
    "        is_property = tf.cast(is_property, tf.int32)\n",
    "\n",
    "        # Find index of label in anomaly_classes, or len(anomaly_classes) if not found\n",
    "        matches = tf.equal(anomaly_classes, label)\n",
    "        anomaly_type = tf.reduce_max(tf.where(matches))\n",
    "        anomaly_type = tf.where(tf.reduce_any(matches), anomaly_type, tf.cast(len(anomaly_classes),tf.int32))\n",
    "        anomaly_type = tf.cast(anomaly_type, tf.int32)\n",
    "\n",
    "        return img, {\n",
    "            \"general_anomaly\": is_anomaly,\n",
    "            \"violence\": is_violent,\n",
    "            \"property_crime\":is_property,\n",
    "            \"anomaly_type\": anomaly_type\n",
    "        }\n",
    "\n",
    "    # Create tf.data.Dataset\n",
    "    image_path = [os.path.normpath(os.path.join(data_dir, row['image'])) for _, row in annotations.iterrows()]\n",
    "    labels = annotations['label'].tolist()\n",
    "\n",
    "    # Filter valid path\n",
    "    valid_indices = [ i for i, path in enumerate(image_path) if os.path.exists(path)]\n",
    "    if len(valid_indices) < len(image_path):\n",
    "        print(f\"WARNING!!: {len(image_path) - len(valid_indices)} invalid image paths found\")\n",
    "        print(\"Sample invalid paths:\", [image_path[i] for i in range(len(image_path)) if i not in valid_indices][:5])\n",
    "\n",
    "    image_path = [image_path[i] for i in valid_indices]\n",
    "    labels = [labels[i] for i in valid_indices]\n",
    "    print(f\"Valid images: {len(image_path)}\")\n",
    "\n",
    "    if not image_path:\n",
    "        print(\"ERROR: No valid images found.\")\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_path, labels))\n",
    "    dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Collect images and labels\n",
    "    images = []\n",
    "    label_dict = {\n",
    "        'general_anomaly':[],\n",
    "        \"violence\": [],\n",
    "        \"property_crime\":[],\n",
    "        \"anomaly_type\": []\n",
    "    }\n",
    "\n",
    "\n",
    "    loaded_counts = 0\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        images.append(batch_image.numpy())\n",
    "        for task in label_dict:\n",
    "            label_dict[task].append(batch_labels[task].numpy())\n",
    "        loaded_counts += len(batch_images)\n",
    "        print(f\"Processed {loaded_counts} images....\", end='\\r')\n",
    "\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    for task in label_dict:\n",
    "        label_dict[task] = np.concatenate(label_dict[task], axis=0)\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"\\nLoaded {loaded_counts} images from {annotation_file}\")\n",
    "    print(\"Image array shape:\", images.shape)\n",
    "    print(\"Label shapes: {task: label_dict[task].shape for task in label_dict}\")\n",
    "    print(f\"Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data .....\")\n",
    "X_train, y_train = load_ucf_crime_data(DATA_DIR, TRAIN_ANNOTATION_FILE, IMAGE_SIZE, BATCH_SIZE)\n",
    "print(\"\\nLoading validation data............\")\n",
    "X_val, y_val = load_ucf_crime_data(DATA_DIR, TEST_ANNOTATION_FILE, IMAGE_SIZE, BATCH_SIZE)\n",
    "\n",
    "# verify data shapes\n",
    "print(\"\\nTraining images shape:\", X_train.shape)\n",
    "print(\"Training labels:\", {task: y_train[task].shape for task in y_train})\n",
    "print(\"Validation images shape:\", X_val.shape)\n",
    "print(\"Validation labels:\", {task: y_val[task].shape for task in y_val})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942d0ec",
   "metadata": {},
   "source": [
    "# Stage 4: Model Definition\n",
    "Define the MTL model with a ResNet50 backbone and four task-specific heads using build_mtl_model. Display the model summary for inspection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mtl_model(input_shape=(224, 224, 3), num_anomaly_types=14):\n",
    "    \"\"\"\n",
    "    Build MTL model with shared ResNet50 backbone and task-specific heads for images.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    pooled = layers.GlobalAveragePooling2D()(x)\n",
    "    shared_dense = layers.Dense(512, activation='relu')(pooled)\n",
    "    \n",
    "    anomaly_output = layers.Dense(1, activation='sigmoid', name='general_anomaly')(shared_dense)\n",
    "    violence_output = layers.Dense(1, activation='sigmoid', name='violence')(shared_dense)\n",
    "    property_output = layers.Dense(1, activation='sigmoid', name='property_crime')(shared_dense)\n",
    "    type_output = layers.Dense(num_anomaly_types, activation='softmax', name='anomaly_type')(shared_dense)\n",
    "    \n",
    "    model = models.Model(inputs, [\n",
    "        anomaly_output, violence_output, property_output, type_output\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model and display summary\n",
    "model = build_mtl_model(input_shape=(224, 224, 3), num_anomaly_types=NUM_ANOMALY_TYPES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4acec21",
   "metadata": {},
   "source": [
    "# Stage 5: Task Relationship Functions\n",
    "Define functions to analyze task relationships: compute_gradient_alignment (cosine similarity of gradients) and compute_loss_correlation (Pearson correlation of losses).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_alignment(model, data, labels, task_names):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between gradients of tasks.\n",
    "    \"\"\"\n",
    "    gradients = {}\n",
    "    for task in task_names:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(data)\n",
    "            task_idx = task_names.index(task)\n",
    "            loss = tf.keras.losses.binary_crossentropy(labels[task], predictions[task_idx])\n",
    "            if task == 'anomaly_type':\n",
    "                loss = tf.keras.losses.sparse_categorical_crossentropy(labels[task], predictions[task_idx])\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        gradients[task] = grads\n",
    "    \n",
    "    similarities = {}\n",
    "    for task1 in task_names:\n",
    "        for task2 in task_names:\n",
    "            if task1 >= task2:\n",
    "                continue\n",
    "            g1 = tf.concat([tf.reshape(g, [-1]) for g in gradients[task1] if g is not None], axis=0)\n",
    "            g2 = tf.concat([tf.reshape(g, [-1]) for g in gradients[task2] if g is not None], axis=0)\n",
    "            cos_sim = tf.reduce_sum(g1 * g2) / (tf.norm(g1) * tf.norm(g2))\n",
    "            similarities[f'{task1}_vs_{task2}'] = cos_sim.numpy()\n",
    "    \n",
    "    print(\"Computed gradient similarities:\", similarities)\n",
    "    return similarities\n",
    "\n",
    "def compute_loss_correlation(losses_dict, task_names):\n",
    "    \"\"\"\n",
    "    Compute Pearson correlation between task losses.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    for task1 in task_names:\n",
    "        for task2 in task_names:\n",
    "            if task1 >= task2:\n",
    "                continue\n",
    "            corr, _ = pearsonr(losses_dict[task1], losses_dict[task2])\n",
    "            correlations[f'{task1}_vs_{task2}'] = corr\n",
    "    print(\"Computed loss correlations:\", correlations)\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47639eb4",
   "metadata": {},
   "source": [
    "# Stage 6: Training Function\n",
    "Define train_mtl_model to train the MTL model, compute task relationships, and return training history. Monitor training progress via printed outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47616fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mtl_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train MTL model and collect losses for correlation analysis.\n",
    "    \"\"\"\n",
    "    task_names = ['general_anomaly', 'violence', 'property_crime', 'anomaly_type']\n",
    "    losses_dict = {task: [] for task in task_names}\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'general_anomaly': 'binary_crossentropy',\n",
    "            'violence': 'binary_crossentropy',\n",
    "            'property_crime': 'binary_crossentropy',\n",
    "            'anomaly_type': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        loss_weights={\n",
    "            'general_anomaly': 1.0,\n",
    "            'violence': 0.5,\n",
    "            'property_crime': 0.5,\n",
    "            'anomaly_type': 1.0\n",
    "        },\n",
    "        metrics={\n",
    "            'general_anomaly': ['accuracy', tf.keras.metrics.AUC(name='auc')],\n",
    "            'violence': ['accuracy'],\n",
    "            'property_crime': ['accuracy'],\n",
    "            'anomaly_type': ['accuracy']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        [y_train[task] for task in task_names],\n",
    "        validation_data=(X_val, [y_val[task] for task in task_names]),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    for task in task_names:\n",
    "        losses_dict[task] = history.history[f'{task}_loss']\n",
    "    \n",
    "    grad_similarities = compute_gradient_alignment(model, X_val[:batch_size], y_val, task_names)\n",
    "    loss_correlations = compute_loss_correlation(losses_dict, task_names)\n",
    "    \n",
    "    return history, grad_similarities, loss_correlations\n",
    "\n",
    "# Train model (uncomment to run after verifying previous stages)\n",
    "# history, grad_similarities, loss_correlations = train_mtl_model(model, X_train, y_train, X_val, y_val, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175a8b6",
   "metadata": {},
   "source": [
    "# Stage 7: Ablation Study\n",
    "Define ablation_study to evaluate the model with subsets of tasks, reporting AUC for general anomaly detection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study(X_train, y_train, X_val, y_val, tasks_to_include, input_shape=(224, 224, 3), num_anomaly_types=14):\n",
    "    \"\"\"\n",
    "    Train model with a subset of tasks for ablation study.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    pooled = layers.GlobalAveragePooling2D()(x)\n",
    "    shared_dense = layers.Dense(512, activation='relu')(pooled)\n",
    "    \n",
    "    outputs = []\n",
    "    loss_dict = {}\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    for task in tasks_to_include:\n",
    "        if task in ['general_anomaly', 'violence', 'property_crime']:\n",
    "            output = layers.Dense(1, activation='sigmoid', name=task)(shared_dense)\n",
    "            loss_dict[task] = 'binary_crossentropy'\n",
    "            metrics_dict[task] = ['accuracy']\n",
    "        elif task == 'anomaly_type':\n",
    "            output = layers.Dense(num_anomaly_types, activation='softmax', name=task)(shared_dense)\n",
    "            loss_dict[task] = 'sparse_categorical_crossentropy'\n",
    "            metrics_dict[task] = ['accuracy']\n",
    "        outputs.append(output)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss_dict,\n",
    "        metrics=metrics_dict\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        [y_train[task] for task in tasks_to_include],\n",
    "        validation_data=(X_val, [y_val[task] for task in tasks_to_include]),\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    val_preds = model.predict(X_val)\n",
    "    general_idx = tasks_to_include.index('general_anomaly') if 'general_anomaly' in tasks_to_include else None\n",
    "    if general_idx is not None:\n",
    "        auc = roc_auc_score(y_val['general_anomaly'], val_preds[general_idx])\n",
    "        print(f\"AUC for tasks {tasks_to_include}: {auc:.4f}\")\n",
    "        return auc\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112054fc",
   "metadata": {},
   "source": [
    "# Stage 8: Execution and Results\n",
    "Run the pipeline, train the model, compute task relationships, and perform the ablation study. Display results for gradient alignment, loss correlation, and AUC scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history, grad_similarities, loss_correlations = train_mtl_model(\n",
    "    model, X_train, y_train, X_val, y_val, epochs=EPOCHS, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Print task relationship results\n",
    "print(\"\\nGradient Alignment (Cosine Similarity):\")\n",
    "for pair, sim in grad_similarities.items():\n",
    "    print(f\"{pair}: {sim:.4f}\")\n",
    "\n",
    "print(\"\\nLoss Correlation (Pearson):\")\n",
    "for pair, corr in loss_correlations.items():\n",
    "    print(f\"{pair}: {corr:.4f}\")\n",
    "\n",
    "# Perform ablation study\n",
    "task_combinations = [\n",
    "    ['general_anomaly'],\n",
    "    ['general_anomaly', 'violence', 'property_crime'],\n",
    "    ['general_anomaly', 'anomaly_type'],\n",
    "    ['general_anomaly', 'violence', 'property_crime', 'anomaly_type']\n",
    "]\n",
    "\n",
    "print(\"\\nAblation Study Results (AUC for General Anomaly Detection):\")\n",
    "for tasks in task_combinations:\n",
    "    auc = ablation_study(X_train, y_train, X_val, y_val, tasks)\n",
    "    if auc is not None:\n",
    "        print(f\"Tasks: {tasks}, AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
